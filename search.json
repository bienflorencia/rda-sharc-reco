[
  {
    "objectID": "abbreviations.html",
    "href": "abbreviations.html",
    "title": "Abbreviations",
    "section": "",
    "text": "Abbreviation\nDefinition\n\n\n\n\nAGA\nAnnotated Grant Agreement\n\n\nAGU\nAmerican Geophysical Union\n\n\nALLEA\nAll European Academies\n\n\nANR\nAgence Nationale de Recherche (French National Research Agency)\n\n\nBoF\nBirds of a Feather\n\n\nCARE\nCollective benefit, Authority to control, Responsibility, Ethics\n\n\nChatGPT\nChat Generative Pre-trained Transformer\n\n\nCLACSO\nConsejo Latinoamericano de Ciencias Sociales\n\n\nCoARA\nCoalition for Advancing Research Assessment\n\n\nCODATA\nCommittee On Data\n\n\nCRediT\nContributor Roles Taxonomy\n\n\nCUDOS\nCommunality, Universalism, Disinterestedness and Organised Scepticism\n\n\nDDOR\nDirection des données ouvertes de la recherche (DDOR) du CNRS\n\n\nDMP\nData Management Plan\n\n\nDEIA\nDiversity, Equity, Inclusion, and Accessibility\n\n\nDOI\nDigital Object Identifier\n\n\nDORA\nDeclaration On Research Assessment\n\n\nFAIR\nFindable, Accessible, Interoperable, Reusable\n\n\nGERD\nGross domestic Expenditure on R&D\n\n\nLMIC\nLow- or Middle-Income Country\n\n\nNIH\nNational Institutes of Health\n\n\nOA\nOpen Access\n\n\nORCID\nOpen Researcher and Contributor ID\n\n\nOS\nOpen Science\n\n\nOS-CAM\nOpen Science Career Assessment Matrix\n\n\nOSTP\nOffice of Science and Technology Policy\n\n\nPID\nPersistent IDentifier\n\n\nRAiD\nResearch Activity Identifier\n\n\nRDA\nResearch Data Alliance\n\n\nRRA\nResponsible Research Assessment\n\n\nSciELO\nScientific Electronic Library Online\n\n\nSCOSS\nSustainability Coalition for Open Science Services\n\n\nSHARC\nSHAring Rewards and Credit\n\n\nTOP\nTransparency Openness Promotion\n\n\nUKRN\nUK Reproducibility Network\n\n\nUNESCO\nUnited Nations Educational, Scientific and Cultural Organisation",
    "crumbs": [
      "Abbreviations"
    ]
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "Before making precise proposals, the ethical framework and the values of science have to be underlined. In the 20th century, the CUDOS norms were characteristics of the science ethos according to Merton (Merton 1942, 1973): Communalism, Universalism, Disinterestedness, Organised Scepticism. However, this system that isolated the scientific community from the rest of the society does not correspond anymore with the more inclusive science and society landscape. The scientific integrity principles and responsibilities, as set out for example in the Second World Conference on Research Integrity (2010), the UNESCO recommendation on Science and Scientific researchers (UNESCO 2017), the UNESCO Recommendation on OS (UNESCO 2021) and the European Code of Conduct for Research Integrity revised in 2023 (ALLEA 2023) mandatory in all EU funded projects, constitute representative international efforts to encourage the development of unified policies with the long-range goal of fostering greater integrity in research worldwide. As these general rules address facets of the research practices and tend to be taken into account both in education and in research assessment criteria, they constitute a general framework for all recommendations below.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#our-values",
    "href": "methodology.html#our-values",
    "title": "Methodology",
    "section": "",
    "text": "Before making precise proposals, the ethical framework and the values of science have to be underlined. In the 20th century, the CUDOS norms were characteristics of the science ethos according to Merton (Merton 1942, 1973): Communalism, Universalism, Disinterestedness, Organised Scepticism. However, this system that isolated the scientific community from the rest of the society does not correspond anymore with the more inclusive science and society landscape. The scientific integrity principles and responsibilities, as set out for example in the Second World Conference on Research Integrity (2010), the UNESCO recommendation on Science and Scientific researchers (UNESCO 2017), the UNESCO Recommendation on OS (UNESCO 2021) and the European Code of Conduct for Research Integrity revised in 2023 (ALLEA 2023) mandatory in all EU funded projects, constitute representative international efforts to encourage the development of unified policies with the long-range goal of fostering greater integrity in research worldwide. As these general rules address facets of the research practices and tend to be taken into account both in education and in research assessment criteria, they constitute a general framework for all recommendations below.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#preparatory-step-identifying-the-needs-and-research-focus-areas",
    "href": "methodology.html#preparatory-step-identifying-the-needs-and-research-focus-areas",
    "title": "Methodology",
    "section": "Preparatory step: Identifying the needs and research focus areas",
    "text": "Preparatory step: Identifying the needs and research focus areas\nThe first step of our work was a Birds of a Feather (BoF) session held during Research Data Alliance Plenary 9 (Figure 1, step 1). The session focused on the hurdles involved in opening up data and other research outputs in the research process, as well as on rewarding schemes and the extent of their use or absence regarding sharing data and other outputs. The discussions spurred i) the creation of the RDA-SHARC interest group that first focused on the design of a human readable FAIR assessment tool and ii) the establishment of a core evolving sub-working group gathering active members developing guidance and recommendations.\nAs part of this core group (namely, the authors of the present work), we further refined the needs related to recognition throughout i) additional interactive working sessions at RDA plenaries 11, 12, 13, 14, 15, 17, 19 and 20, ii) regular teleconference meetings, emails and asynchronous exchanges (e.g., via Google Doc).",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#agreeing-on-terms-and-concepts-terminology",
    "href": "methodology.html#agreeing-on-terms-and-concepts-terminology",
    "title": "Methodology",
    "section": "Agreeing on terms and concepts: terminology",
    "text": "Agreeing on terms and concepts: terminology\nThe preparatory step led us to develop a terminology with regards to rewarding in science as a common understanding of the terms and concepts mapping this landscape (Figure 1, step 2). We identified all related terms we could think of as to research recognition schemes and categorised them as different types of possible rewards and reward mechanisms (see our Terminology).\nFrom the literature, we agreed that types of rewarding can range from intangible reputational rewards such as recognising the contribution made by collaborators through acknowledgments and citations (Hicks 2012), to co-authorship (Latour and Woolgar 1979) and other tangible rewards (e.g., funds, prizes, career advancement, hiring, and patents) (Haeussler et al. 2014; Nelson 2016; Shibayama and Lawson 2021). Opportunities of future collaboration were also reported as possible rewards for sharing (Haeussler et al. 2014; Shibayama and Lawson 2021).",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#developing-mapping-tools",
    "href": "methodology.html#developing-mapping-tools",
    "title": "Methodology",
    "section": "Developing mapping tools",
    "text": "Developing mapping tools\nTo further facilitate the use of our recommendations, as a third step (Figure 1) we built several mapping tools that compiled existing policies and rewards related-tools:\n\nOS Policies, gathers brief descriptions and links to the main OS policies across many countries, pointing to rewards related information whenever specified;\nRewarding tools (OS Awards/Prizes, OS Funds, OS Badges/Certificates/Tokens, OS Champions), display examples of existing rewarding tools that were brought to our attention along the various discussions conveyed within SHARC’s meetings, RDA plenaries and as a result of the SHARC OS survey (described in the next section).",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#developing-recommendations",
    "href": "methodology.html#developing-recommendations",
    "title": "Methodology",
    "section": "Developing recommendations",
    "text": "Developing recommendations\nThe fourth step focused on developing actionable recommendations based on the gaps identified during the SHARC IG working sessions and meetings (Figure 1, step 4). These recommendations aimed to i) guide researchers and scientists in the existing rewarding landscape as to how to get some credit in practice, and ii) raise awareness among a number of actors who are part of the research assessment system on which rewarding mechanisms (so far missing) to provide and implement to make the whole system work.\nTo that aim, a survey was first designed to identify perceptions and expectations of various research communities regarding how OS activities are taken into consideration and rewarded; this survey was sent out to the RDA community at large and various other networks related to members of our core group. Details of the survey methodology and results are available in Grattarola et al. (2024). We then developed the set of recommendations as a multiple-step process based on the results of the survey with back-and-forth exchanges between members of the RDA-SHARC core group and participants in the RDA-SHARC sessions.\n\n\n\n\n\n\nFigure 1: Flowchart of developing the RDA-SHARC IG Recommendations on Open Science rewards and incentives to various stakeholders. The process included 4 steps, namely: 1) identifying the needs and research focus areas, 2) agreeing on terms and concepts (developing rewards-related terminology), 3) mapping existing policies and rewarding initiatives, 4) developing a set of recommendations as a single cycle series of steps involving SHARC IG meetings, a global survey and feedback from RDA sessions.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Recommendations on Open Science Rewards and Incentives",
    "section": "",
    "text": "Open Science contributes to the collective building of scientific knowledge and societal progress. However, academic research currently fails to recognise and reward efforts to share research outputs. Yet it is crucial that such activities be valued, as they require considerable time, energy, and expertise to make scientific outputs usable by others, as stated by the FAIR principles. To address this challenge, several bottom-up and top-down initiatives have emerged to explore ways to assess and credit Open Science activities (e.g., Research Data Alliance, RDA) and to promote the assessment of a broad spectrum of research outputs, including datasets and software (e.g., Coalition for Advancement of Research Assessment, CoARA). As part of the RDA-SHARC (SHAring Rewards and Credit) interest group, we have developed a set of recommendations to help implement various rewarding schemes at different levels. The recommendations target a broad range of stakeholders. For instance, institutions are encouraged to provide digital services and infrastructure, organise training and cover expenses associated with making data available for the community. Funders should establish policies requiring open access to data produced by funded research and provide corresponding support. Publishers should favour open peer-review models and open access to articles, data and software. Government policymakers should set up a comprehensive Open Science strategy, as recommended by UNESCO and followed by a growing number of countries. The present work details different measures that are proposed to the stakeholders. The need to include sharing activities in research evaluation schemes as an overarching mechanism to promote Open Science practices is specifically emphasised.\nKeywords: Open Science, Open Access, FAIR, rewards, sharing, research evaluation",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Science is a cumulative process (Merton 1973) that relies on previous knowledge considering all types of research outputs (Dasgupta and David 1994; Walsh, Cohen, and Cho 2007). Although sharing research outputs as common goods should be the common rule, this is actually not the case.\nThe Open Science (OS) movement was forged in response to this concern. It refers to a range of activities (Grattarola et al. 2024) including sharing research outputs. OS enables replication, improves productivity, limits redundancy, and helps create more robust research methods and a rich network of resources, thus increasing research efficiency (Murray and O’Mahony 2007; Walsh, Cohen, and Cho 2007; Shibayama and Baba 2011). In the end, it contributes to the collective building of scientific knowledge and societal progress (Cole et al. 2024).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#why-open-science-is-important",
    "href": "introduction.html#why-open-science-is-important",
    "title": "Introduction",
    "section": "",
    "text": "Science is a cumulative process (Merton 1973) that relies on previous knowledge considering all types of research outputs (Dasgupta and David 1994; Walsh, Cohen, and Cho 2007). Although sharing research outputs as common goods should be the common rule, this is actually not the case.\nThe Open Science (OS) movement was forged in response to this concern. It refers to a range of activities (Grattarola et al. 2024) including sharing research outputs. OS enables replication, improves productivity, limits redundancy, and helps create more robust research methods and a rich network of resources, thus increasing research efficiency (Murray and O’Mahony 2007; Walsh, Cohen, and Cho 2007; Shibayama and Baba 2011). In the end, it contributes to the collective building of scientific knowledge and societal progress (Cole et al. 2024).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#how-modern-science-is-recognised",
    "href": "introduction.html#how-modern-science-is-recognised",
    "title": "Introduction",
    "section": "How modern science is recognised",
    "text": "How modern science is recognised\nTo appreciate any contribution to science, credit and recognition are a prerequisite to any ‘reward mechanism’ and need to be mapped in the overall research assessment scheme. Crediting is the explicit recognition for one’s contribution to a work, the process whereby the origin of a scientific work is attributed to an individual, a group of individuals or an institution (Merton 1973; Shibayama and Baba 2011; Walsh, Cohen, and Cho 2007). It is the first step in recognising the value of one’s work and is generally quantified by a series of metrics. It is an important process which builds scientists’ reputation. Crediting can be seen as a milestone in the process of rewarding which encompasses several elements such as academic promotion, grants, dedicated staff and support materials that help produce subsequent discoveries (Latour and Woolgar 1979; Shibayama and Lawson 2021). In the case of published discoveries, credit is allocated by the community through attribution, peer review approval, and citation. It can also come from patenting in some specific cases (ALLEA 2023). Sharing intermediate or pre-publication outputs is however far less established as it is more complex and does not necessarily fit into the conventional crediting system of science (Shibayama and Lawson 2021). A number of studies have underlined that academic research fails to recognise, value, and reward efforts to open up the scientific process (Hicks et al. 2015; Munafò et al. 2017; Wilsdon et al. 2015; Wouters et al. 2015). Yet it is crucial that these activities be valued as they require considerable time, energy and expertise to make outputs findable and accessible and for data and software to be compliant with international standards making them interoperable and reusable by others, as stated by the FAIR principles (Wilkinson et al. 2016).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#the-current-sharing-practice-of-academics",
    "href": "introduction.html#the-current-sharing-practice-of-academics",
    "title": "Introduction",
    "section": "The current sharing practice of academics",
    "text": "The current sharing practice of academics\nIn the ‘publish or perish’ culture, some outputs (such as data, databases, or algorithms) may provide academics with an advantage under high competition which can lead them not to share those (Merton 1973; Dasgupta and David 1994; Haas and Park 2010; Haeussler et al. 2014). Moreover, some commercialisation contexts, regulatory constraints, privacy issues or data reuse concerns as well as shortage of funds, lack of time or of capacities and technical resources, could also be barriers (Haas and Park 2010; Walsh, Cohen, and Cho 2007). As a result, the amount of outputs shared through open mechanisms is still limited in many communities or disciplines, and a lot of resources are shared in one-to-one transactions (Shibayama and Baba 2011; Tenopir et al. 2015; Wallis, Rolando, and Borgman 2013). Thus, the degree of openness is still mainly at the discretion of individual academics (Blume 1974; Hackett 2008; Nelson 2016). However, academics broadly agree that open sharing is beneficial to science and numerous studies showed that when requested, it is respected (Czarnitzki, Grimpe, and Pellens 2015; Haas and Park 2010; Shibayama and Baba 2011; Walsh, Cohen, and Cho 2007). Now a clear consensus on how outputs should be shared and rewarded needs to be established.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#the-current-normative-incentives-for-sharing",
    "href": "introduction.html#the-current-normative-incentives-for-sharing",
    "title": "Introduction",
    "section": "The current normative incentives for sharing",
    "text": "The current normative incentives for sharing\nSince the Budapest Declaration (BOAI 2002), that specifically propelled the Open Access (OA) concept, governments, funders, research organisations and publishers are increasingly adopting formal OS policies (Manco 2022) with a primary focus on OA to publications and underlying research data. Pioneers in adopting such policies include, for example, Scientific Electronic Library Online (SciELO), the National Institutes of Health (NIH), White House’s Office of Science and Technology Policy (OSTP), Gates Foundation, Wellcome Trust, UK research councils, Harvard University and Queensland University of Technology. In spite of this, the sharing activities are often not sufficiently recognised or credited in formal assessments of researchers and project proposals, discouraging researchers from engaging in sharing activities (Arthur et al. 2021).\nEfforts to address this challenge have led to the rise of several initiatives within the Responsible Research Assessment (RRA) movement. Notable examples are the DORA declaration (DORA 2012), the Dutch initiative ‘Science in Transition’ (Dijstelbloem et al. 2013), the Leiden Manifesto (Hicks et al. 2015) and the Metric Tide (Wilsdon et al. 2015). While these initiatives have not directly focused on recognising and rewarding OS practices, they have significantly contributed to promoting responsible metrics and the assessment of a broad spectrum of research outputs, including datasets and software.\nThe most notable initiatives that explicitly incorporated OS into the RRA discourse have emerged in the European Union. For example, the European Commission established a Working Group in 2016 on rewards under OS that formulated the OS Career Assessment Matrix (OS-CAM), suggesting various criteria for incorporating OS activities in the formal evaluations of researchers at all career stages (European Commission, Directorate-General for Research and Innovation et al. 2017). Moreover, the European Research Area Policy Agenda for 2022-2024 (EC DGRI 2021) has set the transformation of research assessment systems as a priority strategic action, including the rewarding of OS practices as part of this necessary change, further supported by the Conclusions of the Council of the European Union on Research Assessment and Implementation of OS (EU Council 2022). In line with this agenda, the Coalition for Advancing Research Assessment (CoARA 2022) was formed in 2022, as an initiative from several European organisations, bringing together stakeholders from the research ecosystem across 164 countries to enhance and harmonise research assessment practices, with an emphasis on recognising and rewarding behaviours underpinning OS activities. Additionally, the Horizon Europe programme has incorporated OS into its evaluation of all research proposals and project assessments, showcasing a prime example of how these practices can be embedded in funder evaluation schemes (EU AGA 2023; EU Parliament and Council 2021). Also, the ongoing Horizon Europe projects ‘GraspOS’ (EU Horizon RIA GraspOS project 2023) and ‘OPUS’ (project 2022) have been specifically designed to support the reforms of research assessment systems that include OS practices. Lastly, cOAlition S funders, including the European Commission, have recently introduced a proposal named ‘Towards Responsible Publishing’ (cOAlition S 2023), which calls for the incorporation of OS practices into funders’ assessment policies and the elimination of journal metrics in the evaluation of researchers.\nSome countries have also initiated steps to integrate OS practices into their research assessment schemes, with notable efforts seen in the Netherlands (VNSU et al. 2019), France (CNRS 2019), Norway (UHR Working Group 2021), Finland (Working group for responsible evaluation of a researcher 2020) and in Latin America and the Caribbean (CLACSO 2019). Details and more initiatives are given by Rijcke et al. (2023). Simultaneously, bottom-up international initiatives have emerged to explore more immediate ways to assess and credit OS activities. Notably, the data science community is getting organised under the umbrella of the Research Data Alliance (RDA) to articulate related concerns and offer recommendations (e.g., R.-S. IG 2017; R.-E. IG 2023; and WG 2024).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#objective",
    "href": "introduction.html#objective",
    "title": "Introduction",
    "section": "Objective",
    "text": "Objective\nIn this paper, we provide a set of recommendations developed by the RDA-SHARC interest group to help implement various rewarding schemes for opening up science. These recommendations specifically emphasise the need to include sharing activities in research evaluation schemes as an overarching, valuable, and hopefully efficient mechanism to promote OS practices. The recommendations target a broad range of stakeholders in research and innovation systems, as highlighted by the UNESCO Recommendation on OS (UNESCO 2021), emphasising the collaborative effort of individual researchers, research institutions and any organisation performing research (public and private), funders, government policymakers and publishers in transforming the research culture towards OS (Nosek et al. 2023).",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bibliography"
  },
  {
    "objectID": "mapping_tools/os_funds.html",
    "href": "mapping_tools/os_funds.html",
    "title": "OS Funds",
    "section": "",
    "text": "Tips\n\n\n\n\nYou can resize columns by click-and-dragging the borders.\nYou can search for content in the table in the top-right Search box.",
    "crumbs": [
      "Mapping tools",
      "Rewarding tools",
      "OS Funds"
    ]
  },
  {
    "objectID": "mapping_tools/os_policies.html",
    "href": "mapping_tools/os_policies.html",
    "title": "OS Policies",
    "section": "",
    "text": "Tips\n\n\n\n\nYou can resize columns by click-and-dragging the borders.\nYou can search for content in the table in the top-right Search box."
  },
  {
    "objectID": "individual.html",
    "href": "individual.html",
    "title": "Recognition at the individual level",
    "section": "",
    "text": "Examples: National policies"
  },
  {
    "objectID": "individual.html#be-aware-of-the-existing-nationalinstitutional-policiesagreements-relevant-to-your-research-situation-in-your-institution-country-or-region",
    "href": "individual.html#be-aware-of-the-existing-nationalinstitutional-policiesagreements-relevant-to-your-research-situation-in-your-institution-country-or-region",
    "title": "Recognition at the individual level",
    "section": "",
    "text": "Examples: National policies"
  },
  {
    "objectID": "individual.html#be-aware-of-os-training-sessions-and-resources-provided-in-your-institution-or-community",
    "href": "individual.html#be-aware-of-os-training-sessions-and-resources-provided-in-your-institution-or-community",
    "title": "Recognition at the individual level",
    "section": "Be aware of OS training sessions and resources provided in your institution or community",
    "text": "Be aware of OS training sessions and resources provided in your institution or community\nExamples: OS & FAIR training initiatives | UNESCO’s index"
  },
  {
    "objectID": "individual.html#maximise-your-visibility-citation-out-of-your-open-science-work",
    "href": "individual.html#maximise-your-visibility-citation-out-of-your-open-science-work",
    "title": "Recognition at the individual level",
    "section": "Maximise your visibility citation out of your open science work",
    "text": "Maximise your visibility citation out of your open science work\n\nPre-requisite on digital presence:\n\n\nMaximise as much as possible your digital presence using PID for you and for all your outputs (ex/ ORCID, DOI or other identifier for OA publications / OA datasets/ Open source software. Example: Parsec Digital Presence checklist | Unesco.\nUpdate your cv & reporting activities with your OS activites.\n\n\nMake your data & outputs citable\n\n\nInclude citation elements for research data/software you created in the References section of your paper. To support indexing and reuse:\n\nUse American Psychological Association (APA) style.\n\nInclude a persistent identifier (DOI), preferred, or URL.\n\nUse labels/bracketed descriptions (e.g., [Dataset], [Software], [Collection], [ComputationalNotebook]).\n\n\nInclude a data/software availability statement in your paper that describes where and how your data are available, and how to cite them if possible. Refer to templates for detailed information. Example: AGU\n\n\nAcknowledge OS contributorship\n\n\nRecognise all kind of contributorship early in the projects. Example: Acknowledging Contributors - The Turing Way\n\nUse the CRediT taxonomy:\n\nAllocate the terms appropriately to your own contribution and to contributors within research outputs.\n\nAdvocate that your institution and any publications you’re submitting to acknowledge and adopt the taxonomy. Example: Implementing CRediT\n\n\n\nCite or acknowledge other’s OS activities using DOis or other PIDs\n\n\nInclude data citations for all research data you used in the References section of your paper.\n\nAcknowledge any OS tool you may use , e.g. with their identifier or ‘How to cite’ statement (if any). More information: RDA WG"
  },
  {
    "objectID": "individual.html#get-financial-reward-or-support",
    "href": "individual.html#get-financial-reward-or-support",
    "title": "Recognition at the individual level",
    "section": "Get financial reward or support",
    "text": "Get financial reward or support\n\nApply to specific funds for OS activities if any.\n\nApply to OS prize/awards if any.\nAnticipate an OS budget in your research funding applications.\nExamples: Compilation of existent award/prizes"
  },
  {
    "objectID": "individual.html#get-symbolic-reward",
    "href": "individual.html#get-symbolic-reward",
    "title": "Recognition at the individual level",
    "section": "Get symbolic reward",
    "text": "Get symbolic reward\n\nApply for OS certificates/OS ambassador/OS badge schemes.\n\nApply for training badges.\n\nJoin OS acknowledging opportunities to gain visibility/reputation.\nExamples: Compilation of existent symbolic rewards"
  },
  {
    "objectID": "publishers.html",
    "href": "publishers.html",
    "title": "To publishers",
    "section": "",
    "text": "Piwowar and Chapman (2008) investigated the data sharing policies of 70 journals and found that researchers more frequently share data when journals have such a policy, and that the probability of sharing data correlates positively with the strength of the policy (Mongeon et al. 2017). Publishers’ policies are therefore key for OS implementation. Over time many have established sharing policies in line with recommendations to research funders and institutions, yet there is a need for journals to provide clearer instructions to authors, reviewers and staff to encourage OS and foster rewarding schemes for it.\nJournals should facilitate researcher-authors’ compliance with good OS practices as a prerequisite to credit. This entails implementing a number of connected measures: first, establishing a clear mandate to use unique PIDs for both individuals and their research outputs to enable their digital connectivity to the scholarly record and the attribution of their work; second, making a clear request that all data and software related to a published manuscript adhere to the FAIR principles, along with providing guidance on how to do so and where to deposit these resources to enable reuse; third, providing support for preprints would also help facilitate open access; and fourth, requiring the full and proper citation of all data and software, whether created, used or reused from others’ research, in all publications, as it is indispensable for receiving credit.\nRequesting FAIR data and software implies that editorial staff and reviewers are able to verify proper citation of data and software and ensure that all supplementary resources are openly available, free of charge, even if the article is not. For this, journals should assign specific editors, such as ‘data editors’, to assess the quality and FAIRness of data and software (e.g., The American Naturalist). By supporting the FAIR principles in their policies, in combination with clear instructions on how authors should comply, will aid the journals in making strides towards more automated reviews.\nThe peer-reviewing activity is essential to the scientific method, and publishers should endeavour to recognise its importance and promote transparency through open peer-reviewing models (with or without reviewers anonymity). This can be an additional way to expand OS and improve responsible research assessment. Journals should systematically implement existing tools, such as the CRediT taxonomy, to enable clarifying one’s contribution/roles in research works, and systematically use existing guidelines such as the TOP Factor, which can assess their openness and transparency.\nFinally, to foster greater inclusivity it is crucial to reconsider the current calibration of OA publishing fees, which are based solely on a country’s GDP for Low- and Middle-Income Countries (LMICs). This approach unfairly impacts countries like for instance Uruguay, where GDP is not considered to be low while their R&D funding is; In such cases, it is imperative to employ more meaningful economic indicators to mitigate the exacerbation of disparities in global knowledge access and to calibrate more equitable costs. Programs such as Research4Life provide one mechanism for use by publishers to try to calibrate costs. More concrete examples are provided in Table 3.\n\n\nTable 3: Recommendations to Publishers\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nMongeon, P., N. Robinson-Garcia, W. Jeng, and R. Costas. 2017. “Incorporating Data Sharing to the Reward System of Science: Linking DataCite Records to Authors in the Web of Science.” Aslib Journal of Information Management 69 (5): 545–56. https://doi.org/10.1108/AJIM-01-2017-0024.\n\n\nPiwowar, Heather A., and Wendy W. Chapman. 2008. “Identifying Data Sharing in Biomedical Literature.” AMIA Annual Symposium Proceedings 2008: 596–600. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2655927/.",
    "crumbs": [
      "Recommendations",
      "To publishers"
    ]
  },
  {
    "objectID": "research_performing_organisations.html",
    "href": "research_performing_organisations.html",
    "title": "To research performing organisations",
    "section": "",
    "text": "To gain insight and learn how to support OS activities, institutions should first join RRA and OS related communities/initiatives (e.g., CoARA, RDA) and encourage their personnel to be active in them. Formal OS policies should be adopted and posted on institutional websites, ideally in a discoverable and usable format (e.g. human and machine readable), and communicated to the communities they serve. Important to these policy measures, research outputs should be deposited in community trusted repositories (e.g., institutionally supported repositories, CoreTrustSeal) and made publicly available and reusable under permissive licences. To make these outputs fully reusable, a data management plan (DMP) should be required for all research projects and FAIR principles should be applied as much as possible. In particular, all publications (co)-authored by researchers/staff and students should contain ‘Data Availability Statements’ and data citation references (which applies to other research outputs such as software).\nFurthermore, OS practices expected by a policy should be monitored and rewarded, implying that they should be considered as part of criteria for recruitment and evaluation. A prerequisite for OS monitoring is engagement with persistent identifier (PID) infrastructures, such as Datacite which enables tracking OS activities and outputs through relevant metadata. Even though openly shared datasets, software, protocols, and other research outputs are increasingly accompanied with Digital Object Identifiers (DOIs) and can be tracked, these efforts are not always fully credited as part of research evaluation and recruitment procedures. There is a need to develop new metrics and indicators for evaluating OS practices, aligning with principles of openness, transparency, and collaboration, and thereby crediting the creator. Assessing scientific production traditionally relies on citation-based metrics from databases like Web of Science, or Google Scholar. However, further discussions in the research community have moved beyond traditional metrics [from PubMed Medline, Scopus etc.; Datacite (2024)] and have explored alternative approaches potentially more suited to OS activities (Das 2015; Ugwu Okechukwu et al. 2023; Bosman, Debackere, and Cawthorn 2024).\nCapacity building is critical to implement OS policies. Improvements in OS capacity building should be made by incorporating OS education into research workflows (such as in curricula, training programs, and working groups), so as to become part of the culture. Infrastructures and material resources for OS such as providing digital services and tools should be facilitated by institutions (e.g., FAIR data management service, DMP tools, tools for anonymization, and guidance towards trusted repositories). Notably, OS practice should be facilitated and streamlined by services wherever relevant such as automated metadata completion via persistent identifiers and transfer and communication of copyrights and intellectual property rights should be retained to comply with OA and OS requirements.\nAnother important aspect is the financial support for OS, including PID-related costs such as DOI registration for all research outputs such as datasets, costs associated with research data/software management, investments in national/regional OS initiatives such as Diamond OA. In order to support OS activities, it is important to include related costs in funding applications, create funding opportunities to work with relevant OS communities, and establish other incentives for OS activities. Various types of OS rewarding solutions need to be explored and implemented, ranging from awards, salary bonuses, champions, badging schemes, to additional free time (e.g., sabbaticals), depending on context. These should also be integrated and recognized as part of recruitment, promotion and tenure schemes (e.g., recognizing open access to research outputs). Token recognition systems (e.g. blockchain backed) are also emerging as a new opportunity to reward the contributions that academics make to the scientific ecosystem. Academics would be awarded token bounties for undertaking common but vital tasks such as peer review, committee work, and writing reports (Finke and Hensel 2024). These tokens would serve as a validated record of scientific contribution that could be used in the research evaluation scheme. This adds to already present citation mechanisms, including data, software, and other research outputs as recognition.\n\n\nTable 1: Recommendations to Research performing organisations\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nBosman, Jeroen, Koenraad Debackere, and William Cawthorn. 2024. “Next Generation Metrics for Scientific and Scholarly Research in Europe.” https://doi.org/10.5281/zenodo.11123148.\n\n\nDas, Anup Kumar. 2015. Research Evaluation Metrics. UNESCO. https://unesdoc.unesco.org/ark:/48223/pf0000232210.\n\n\nDatacite. 2024. “Data-Level Metrics.” https://datacite.org/blog/tag/data-level-metrics/.\n\n\nFinke, Andreas, and Thomas Hensel. 2024. “Decentralized Peer Review in Open Science: A Mechanism Proposal.” https://doi.org/10.48550/arXiv.2404.18148.\n\n\nUgwu Okechukwu, Paul-Chima, Nnenna Ugwu Jovita, Ugo Alum Esther, and Emmanuel I. Obeagu. 2023. “Redefining Academic Performance Metrics: Evaluating the Excellence of Researchers, Academics, and Scholars” 4 (1): 36–42. https://doi.org/10.59298/NIJSES/2023/10.5.1000.",
    "crumbs": [
      "Recommendations",
      "To research performing organisations"
    ]
  },
  {
    "objectID": "terminology.html#mechanismstools-to-provide-a-reward-for-os",
    "href": "terminology.html#mechanismstools-to-provide-a-reward-for-os",
    "title": "Terminology",
    "section": "Mechanisms/tools to provide a reward for OS",
    "text": "Mechanisms/tools to provide a reward for OS",
    "crumbs": [
      "Terminology"
    ]
  },
  {
    "objectID": "acknowledgements.html",
    "href": "acknowledgements.html",
    "title": "Acknowledgements",
    "section": "",
    "text": "Thanks to the contributors to initial phases of the present work:\nRomain David (ERINHA, FR), Alison Specht (University of Queensland, AU), Gabrielle Bertier (University Toulouse III, FR), Mohammed Yahia (INIST, FR), Louise Bezuidenhout (Data Archiving and Networked Services, DANS and Royal, Netherlands Academy of Arts and Sciences, NL), Michele de Rosa (2.-0 LCA consultants, DK), Laurent Dollé (Université Libre de Bruxelles, BE), Sofie Beckaert (University Gent, BE), and Elena Bravo (ISS, IT).\nWe also thank Anne-Sophie Archambeau, Jane Carpenter, Anna Cohen Nabeiro, Aurélie Delavaud, Fiona Murphy, Sophie Parmelon, Anne-Marie Tassé and Martina Zilioli for their inputs.\nFinally, we wish to acknowledge the fruitful comments from all the members of the RDA- SHARC interest group and all the attendants to the various SHARC working sessions held at RDA plenaries.",
    "crumbs": [
      "Acknowledgements"
    ]
  },
  {
    "objectID": "funders.html",
    "href": "funders.html",
    "title": "To funders",
    "section": "",
    "text": "For funders to support OS, it is important that they develop policies that require, or at a minimum, encourage OS activities in their communities and integrate them into their proposal workflows. To develop these policies, funders should gain a better understanding of current open research practices and capabilities, by conducting landscape analyses, engaging with the OS community, leveraging expertise, and identifying initial steps (i.e. low hanging fruits) that can be taken to monitor and guide these activities. Mapping key stakeholders in OS would be prudent, to avoid being overwhelmed and to interface with the OS community via these stakeholders. For reference, the Aligning Science Across Parkinson’s (ASAP 2021) is an example of the more forward-looking funder policies.\nOS monitoring is still a relatively new and developing aspect of the research community where organisations like CoARA and UNESCO are guiding these conversations. However, it is difficult for funders to track these conversations, and it is important for these groups to engage funders, where reasonable (e.g., Centre and ReSA 2024). For instance, to develop a common framework and schema where policy recommendations and requirements can be aligned. These communities, for the funders sake, should also work towards ensuring that the underlying sources and workflows used to provide information for monitoring and assessment are clear. Funders are limited in how they can interface with OS infrastructure, so it is important for infrastructure providers to take a simple approach to how they need funders to provide them with information (for instance, asking funders to interact with APIs or use XML vs CSV). The support of funders like Arcadia for projects such as OpenAlex (Portenoy 2024) underscores the importance of investing in collaborative, open scholarly infrastructure to be used as sources for OS monitoring. This commitment is shared by other funders, such as the Bill & Melinda Gates Foundation and the French National Research Agency, who have demonstrated their support by signing the 2024 Barcelona Declaration of Open Research Information.\nInitiatives like the national PID strategies out of RDA (Brown et al. 2022) are helpful to funders as they outline the required infrastructure components they need to enable OS. An example is RAiD (Research Activity Identifier) which allows funders to interlink outputs and resources, but also better understand (interdisciplinary) collaboration in the projects they fund. Not every funder has the capability to implement a data management plan workflow but an output-based approach is an alternative to monitoring and assessment. In line with PIDs that make researchers outputs searchable and discoverable and guarantee their long-term accessibility and tracing, it is worth mentioning emerging decentralised PID approaches such as dPIDs (Hill, Koellinger, and Van Winkle 2024) and dARK (Matas et al. 2023), as new potential monitoring systems to be explored.\nNew approaches to funding OS need to be explored and implemented, where funding is allocated to support policies. These can be prizes celebrating OS aspects such as the ‘DataWorks! Prize’, developing ‘OS champions’, for instance, at Michael J. Fox Foundation (in the US), encouraging and allocating support for DMPs and data publishing like ANII (in Uruguay). Also, coordination is key as a number of funders are limited by how much they can allocate to OS versus some of the funders that are allocating more towards big initiatives and infrastructure projects. The decision regarding what to fund in OS is more often dependent on the funder’s vision, mission, goals, and values.\nSupporting OS requires certain commitments from funders beyond just infrastructure. Diversity, Equity, Inclusion, and Accessibility (DEIA) should be integrated into programs together with fostering team science, collaboration, and greater transparency, in line with the CARE principles (Russo Carroll, Garba, and Figueroa-Rodriguez 2020). These are key tenets of OS, but it is also important that funders look at which principles and values are important to them and how they align with OS (e.g., supporting preprints and open access for the public good). These principles and values can be used as a compass to help with guiding funders through a dynamic OS landscape. Funders should look internally too on how they dedicate staff time and resources to support OS (e.g., setting up teams and roles).\n\n\nTable 2: Recommendations to Funders\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nASAP. 2021. “ASAP’s Open Access Policy.” https://parkinsonsroadmap.org/open-access-policy/#.\n\n\nBrown, Christopher, Natasha Simons, Daniel Bangert, and Shawna Sadler. 2022. “Research Data Alliance - National PID Strategies Working Group.” 2022. https://www.rd-alliance.org/groups/national-pid-strategies-wg/members/all-members/.\n\n\nCentre, Scilifelab Data, and ReSA. 2024. “2024 International Research Software Funders Workshop.” https://adore.software/2024-international-research-software-funders-workshop/.\n\n\nHill, Christopher, Philipp Koellinger, and Erik Van Winkle. 2024. “THE SCHOLARLY Kitchen. Guest Post — Navigating the Drift: Persistence Challenges in the Digital Scientific Record and the Promise of dPIDs.” March 14, 2024. https://scholarlykitchen.sspnet.org/2024/03/14/guest-post-navigating-the-drift-persistence-challenges-in-the-digital-scientific-record-and-the-promise-of-dpids/.\n\n\nMatas, L., W. Segundo, T. Nobrega, J. E. S. Filho, and J. Mena-Chalco. 2023. “dARK: A Decentralized Blockchain Implementation of ARK Persistent Identifiers. Open Repositories 2023 (OR2023), Stellenbosch, South Africa.” Zenodo. July 10, 2023. https://doi.org/10.5281/zenodo.8091668.\n\n\nPortenoy, Jason. 2024. “OurResearch Blog News from the OurResearch Team. OurResearch Receives $7.5M Grant from Arcadia to Establish OpenAlex, a Milestone Development for Open Science.” March 13, 2024. https://blog.ourresearch.org/ourresearch-receives-7-5m-grant-from-arcadia-to-establish-openalex-a-milestone-development-for-open-science/.\n\n\nRusso Carroll, Stephanie, Ibrahim Garba, and Oscar L. Figueroa-Rodriguez. 2020. “The CARE Principles for Indigenous Data Governance.” Data Science Journal 19 (43): 1–12. https://doi.org/10.5334/dsj-2020-043.",
    "crumbs": [
      "Recommendations",
      "To funders"
    ]
  },
  {
    "objectID": "mapping_tools/os_champions.html",
    "href": "mapping_tools/os_champions.html",
    "title": "OS Champions",
    "section": "",
    "text": "Tips\n\n\n\n\nYou can resize columns by click-and-dragging the borders.\nYou can search for content in the table in the top-right Search box.",
    "crumbs": [
      "Mapping tools",
      "Rewarding tools",
      "OS Champions"
    ]
  },
  {
    "objectID": "mapping_tools/os_badges_certificates_tokens.html",
    "href": "mapping_tools/os_badges_certificates_tokens.html",
    "title": "OS Badges/Certificates/Tokens",
    "section": "",
    "text": "Tips\n\n\n\n\nYou can resize columns by click-and-dragging the borders.\nYou can search for content in the table in the top-right Search box.",
    "crumbs": [
      "Mapping tools",
      "Rewarding tools",
      "OS Badges/Certificates/Tokens"
    ]
  },
  {
    "objectID": "mapping_tools/os_award_prizes.html",
    "href": "mapping_tools/os_award_prizes.html",
    "title": "OS Awards/Prizes",
    "section": "",
    "text": "Tips\n\n\n\n\nYou can resize columns by click-and-dragging the borders.\nYou can search for content in the table in the top-right Search box.",
    "crumbs": [
      "Mapping tools",
      "Rewarding tools",
      "OS Awards/Prizes"
    ]
  },
  {
    "objectID": "researchers.html",
    "href": "researchers.html",
    "title": "To researchers",
    "section": "",
    "text": "At the individual level and in the current research ecosystem, getting some kind of reward from OS activities will result from several distinct mechanisms that people must be aware of.\nFirst, the normative context framing one’s research activity, e.g. in particular national and institutional ones if existent, sets the tone for what must, can or should be done, and sometimes describes how. It is then imperative that everyone is aware of the policies and regulations in place and of the possible means accompanying their implementation. More and more, OS frameworks are endorsed over time worldwide and may provide opportunities to get/apply for various kinds of training and support (material, financial, human). For instance, through specific funds, prizes or awards (see SHARC’s OS Awards/Prizes, OS Funds), or by anticipating an OS budget in the funding applications. Researchers need to watch over this evolving context to anticipate assignments and seize opportunities.\nSecond, a number of actions are necessary to maximise one’s digital presence and visibility on the basis of crediting processes in research (detailed in Stall et al. 2023). The prerequisite for crediting is an identification scheme for researchers and their work’s outputs that is unambiguous, persistent and embedded in the scholarly digital ecosystem. The attribution of a PID with associated rich metadata to a research object, makes it searchable and discoverable and guarantees its long-term accessibility and tracing. This is easily achievable for datasets or databases that are numerical by nature. Regarding physical/material resources, it requires first that their description is somehow digitised and accessible on the web (e.g., via metadata-only datasets, data papers or landing pages). Identification through PIDs is now supported by robust organisations, especially DataCite operating DOIs for numerical objects and ORCID for individual researchers. Making visible those identified elements is the next step to getting or giving credit. It is essential that researchers refer systematically to all their own OS-identified outputs wherever relevant through citation and/or acknowledgement, notably in papers, CVs and reporting activities. It is equally essential that researchers cite or acknowledge other’s outputs they reuse in their own research. This is also intrinsically linked with how co-authorship is managed within projects/teams. It is important to consider the diverse contributor roles and it is advised to establish how to handle co-authorships from the beginning of a project to ensure that everyone’s contribution (including e.g., technicians or data collectors) is included.\nThirdly, obtaining symbolic rewards such as OS badges and certificates or OS ambassador roles can serve as a form of recognition for researchers who engage in OS practices (e.g., Open Science Badges of the Center for Open Science). These recognition schemes can help build trust in the researchers’ work and enhance their credibility as researchers (Schneider et al. 2022). By earning badges, researchers demonstrate their commitment to OS and become visible in their community for that. Having digital badges incorporated into an author’s record as a contribution to overall metrics is to be explored and implemented in research scholarly infrastructures. More practical information is provided in Table 5.\nFinally, credit/recognition can also be obtained for research outputs that have a commercial perspective through patents that may have been obtained based on the results. Obtaining patents means that researchers or their employer legally own intellectual property rights. Researchers should be aware that patenting and OS practices are compatible (EC Innovation Council and SMEs Executive Agency 2023), i.e. open sharing of findings can be done as soon as a patent application is filed or prior to the filing in certain jurisdictions such as the US and South Korea which provide ‘grace periods’ (Nuechterlein et al. 2023). In such cases, advice should be given to the applicant that they should encourage the ‘free non-commercial use by [other] researchers of knowledge disclosed in patents’. Given that large, detailed and consistent datasets are an asset not only for researchers but also for companies, monetary reward opportunities can arise to provide incentives for data sharing (ALLEA 2022).\nFor examples on national and institutional OS plans, OS and FAIR awards, dedicated funds for OS, and training initiatives, please refer to our Rewarding tools (OS Awards/Prizes, OS Funds, OS Badges/Certificates/Tokens, OS Champions).\n\n\nTable 5: Recommendations to Researchers\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nALLEA. 2022. “Aligning Intellectual Property Rights with Open Science - ALLEA Statement.” https://allea.org/wp-content/uploads/2022/04/ALLEA-Statement-Aligning-IPR-with-Open-Science.pdf.\n\n\nEC Innovation Council and SMEs Executive Agency. 2023. “European IP Helpdesk Bulletin. No. 7, December 2023, Open Science.” https://op.europa.eu/en/web/eu-law-and-publications/publication-detail/-/publication/943874e5-9fbc-11ee-b164-01aa75ed71a1.\n\n\nNuechterlein, Anna, Ari Rotenberg, Jeff LeDue, Paul Pavlidis, and Judy Illes. 2023. “Open Science in Play and in Tension with Patent Protections.” Journal of Law and the Biosciences 10 (2): lsad016. https://doi.org/10.1093/jlb/lsad016.\n\n\nSchneider, J., T. Rosman, A. Kelava, and S. Merk. 2022. “Do Open-Science Badges Increase Trust in Scientists Among Undergraduates, Scientists, and the Public?” Psychological Science. https://doi.org/10.1177/09567976221097499.\n\n\nStall, Shelley, Alison Specht, Jennifer Gonçalves Amato, and et al. 2023. “Parsec Digital Presence Checklist.” https://doi.org/10.5281/zenodo.4706118.",
    "crumbs": [
      "Recommendations",
      "To researchers"
    ]
  },
  {
    "objectID": "government-policy-makers.html",
    "href": "government-policy-makers.html",
    "title": "To government policy makers",
    "section": "",
    "text": "The governments’ adoption and promotion of a national OS policy are an important driver for its implementation. It demonstrates political willingness and helps facilitate the harmonisation of practices across a variety of institutions and disciplines: giving common guidelines and a roadmap to all universities and research institutes facilitates a consistent uptake of OS across territory, institutes and disciplines. Some countries have been early in setting up a national OS strategy (Sveinsdottir, Davidson, and Proudman 2021), and a few of them have included rewarding mechanisms such as France (MESR 2021) and the Netherlands (NPOS 2022). In the French national OS plan, a number of measures are mentioned to make OS practices sustainable, among them the requirement for changes in the evaluation system. In the Dutch national OS strategy, a requirement for realising OS is to ‘Make OS rewarding through incentives (Recognition & Rewards)’.\nIt is important to recognise that international reference texts such as the UNESCO Recommendation on OS (UNESCO 2021) have stimulated such national strategies and policies. By the end of 2023, eleven countries had national policies stemming from UNESCO’s OS recommendations (Austria, Colombia, Cyprus, Ireland, Italy, Latvia, Lesotho, Romania, South Africa, Spain and Ukraine), so the number of countries having such national policies had doubled since the recommendation. Four countries included OS principles in their national Science Technology and Innovation policies (Estonia, Ghana, Sierra Leone and Slovenia); eleven countries (Botswana, Côte d’Ivoire, Croatia, Kenya, Mozambique, Namibia, Nigeria, Somalia, United Republic of Tanzania, Uganda and Venezuela) are currently developing OS policies taking into account the UNESCO recommendation though not specifically mentioning rewarding and crediting measures (UNESCO 2023).\nOur overarching recommendation is for governments to develop national OS policies. Table 4 gives examples of such national strategies in various countries that policymakers can adapt to their own contexts. Considering such policies, a number of specific elements need attention.\nFirst, incorporating effective reward mechanisms into national OS policies is important. Providing clear incentives is needed, as opposed to framing OS activities as burdensome requirements. These incentives are vital for fostering the acceptance and successful implementation of OS policies within the scientific community.\nSecond, compiling and documenting use cases via dedicated websites would highlight real-life mechanisms that have been implemented or piloted. Given the substantial diversity among institutions and policies across various domains and contexts, it is clear that rewarding different scientific activities is not a ‘one size fits all’ effort. Showcasing use cases would accelerate the implementation of systems that work effectively across most domains. At the same time, it would accommodate specific mechanisms where necessary. Additionally, it would help avoid repeating mistakes or duplicating efforts.\nThird, systematic and rigorous approaches to analyse OS activities, particularly reward mechanisms, are needed. The French national OS plan, for example, has launched a specific call for research proposals in 2023 to study OS activities, including reward systems. To achieve a comprehensive understanding, we recommend prioritising and encouraging funding for projects dedicated to the in-depth analysis of these mechanisms or providing direct funding for such research initiatives.\nFinally, it is often the case that various practices are established and tools or mechanisms are tested, but this is frequently done in silos, without coordination between institutions. At the national level, such coordination can be organised and highlighted. Thus, facilitating networking and sharing of practices across institutions at the national level is highly recommended. Further, despite international initiatives such as RDA and CoARA that are pivotal for harmonising assessment methods and mechanisms, there is still a notable lack of dedicated efforts to standardise the assessment of rewards for OS activities at the national level across various institutions and disciplines. Addressing this gap should be a priority to advance OS on a global scale.\n\n\nTable 4: Recommendations to Government policy makers\n\n\n\n\n\n\n\n\n\n\n\nReferences\n\nMESR. 2021. “Second French Plan for Open Science: Generalising Open Science in France 2021-2024.” https://www.ouvrirlascience.fr/second-national-plan-for-open-science/.\n\n\nNPOS. 2022. “Open Science 2030 in the Netherlands: NPOS2030 Ambition Document and Rolling Agenda (Approved Version).” https://doi.org/10.5281/zenodo.7433767.\n\n\nSveinsdottir, T., J. Davidson, and V. Proudman. 2021. “An Analysis of Open Science Policies in Europe.” SPARC Europe. https://doi.org/10.5281/zenodo.4725817.\n\n\nUNESCO. 2021. “UNESCO Recommendation on Open Science.” https://doi.org/10.54677/MNMH8546.\n\n\n———. 2023. Open Science Outlook 1: Status and Trends Around the World. United Nations Educational, Scientific; Cultural Organization,. https://doi.org/10.54677/GIIC6829.",
    "crumbs": [
      "Recommendations",
      "To government policy makers"
    ]
  },
  {
    "objectID": "recommendations.html",
    "href": "recommendations.html",
    "title": "Recommendations",
    "section": "",
    "text": "The summary of our recommendations is presented and discussed in the following sections.\n\nRecommendations to research performing organisations\nRecommendations to funders\nRecommendations to publishers\nRecommendations to government policy-makers\nRecommendations to researchers",
    "crumbs": [
      "Recommendations"
    ]
  },
  {
    "objectID": "recommendations.html#overview-and-discussion-of-the-recommendations",
    "href": "recommendations.html#overview-and-discussion-of-the-recommendations",
    "title": "Recommendations",
    "section": "",
    "text": "The summary of our recommendations is presented and discussed in the following sections.\n\nRecommendations to research performing organisations\nRecommendations to funders\nRecommendations to publishers\nRecommendations to government policy-makers\nRecommendations to researchers",
    "crumbs": [
      "Recommendations"
    ]
  },
  {
    "objectID": "concluding_remarks.html",
    "href": "concluding_remarks.html",
    "title": "Concluding remarks",
    "section": "",
    "text": "Opening science today necessitates integrating transformative changes in research culture, workflows, governance structures and assessment mechanisms, and involves extending these changes across all scientific communities. Achieving this goal is not feasible through the efforts of an individual researcher without support from other stakeholders in the research ecosystem and global coordination of their collective actions. These stakeholders include research performing and funding organisations, publishers and government policy makers.\nGiven the historical organisation of science, the transition to OS can be challenging, burdensome, and costly for researchers who generate scientific outputs. Identifying mechanisms to facilitate and reward those at the forefront of this transition is essential for accelerating the entire process. This study has practical implications, providing actionable recommendations that embrace a holistic approach to guide the development and implementation of rewarding schemes at various levels - where they exist, or to assist in their creation where they are needed.\nIt is important to note that incentivising OS practices, such as data sharing, might lead some researchers to engage in strategic sharing to accumulate rewards, effectively ‘gaming’ the system rather than focusing on the production of new, high-quality knowledge. Therefore, to prevent a similar ‘publish or perish’ dynamic within OS practices - where rewards may drive efforts focused more on quantity than on substantive contributions - it is crucial that any OS reward and incentive schemes incorporate stringent eligibility criteria for rewards, based on rigorous quality assessments of outputs and governed by principles of research integrity and responsible conduct.",
    "crumbs": [
      "Concluding remarks"
    ]
  }
]